{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価指標と目的関数\n",
    "\n",
    "・モデルの予測値の評価に用いるのが評価指標であり、目的関数はモデルが学習中に最適化される関数である。\n",
    "\n",
    "・上手く学習を進めるには、目的関数が微分可能である必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カスタム評価指標とカスタム目的関数\n",
    "・モデルやライブラリによっては、提供されていない評価指標や目的関数をユーザーが定義できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss:  0.09399718567695808\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# データセットロード\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data; y = cancer.target\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# xgboostのデータ構造へ変換\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
    "\n",
    "\n",
    "# カスタム評価指標: logloss(xgboostの'binary:logistic'と等価)\n",
    "def logregobj(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    preds = 1.0 / (1.0 + np.exp(-preds))\n",
    "    grad = preds - labels\n",
    "    hess = preds * (1.0 - preds)\n",
    "    return grad, hess\n",
    "\n",
    "# カスタム評価指標: error\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'custom-error', float(sum(labels != (preds > 0.0))) / len(labels)\n",
    "\n",
    "# パラメータ\n",
    "params = {'random_state': 42}\n",
    "num_round = 50\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_round, watchlist, obj=logregobj, feval=evalerror, verbose_eval=0)\n",
    "\n",
    "# 確率値に変換\n",
    "pred_val = bst.predict(dvalid)\n",
    "pred = 1.0 / (1.0 + np.exp(-pred_val))\n",
    "logloss = log_loss(valid_y, pred)\n",
    "print('logloss: ', logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評価指標の最適化\n",
    "\n",
    "## 評価指標最適化のアプローチ\n",
    "\n",
    "例として一部抜粋\n",
    "\n",
    "・評価指標がRMSEやloglossならば、モデルの目的関数も同じものを指定できる。RMSLEならば学習データの目的変数を対数変換し、目的関数をRMSEとして学習させた後、指数関数で変換をもとに戻した予測値を提出する。\n",
    "\n",
    "・異なる評価指標を選択し、それを評価対象としてセットしたEarlyStoppingを用いて、最適になる時点で学習を止める方法。\n",
    "\n",
    "## 閾値の最適化\n",
    "\n",
    "予測確率ではなく、正例か負例のラベルを提出する評価指標においては、通常は予測確率からある閾値で分けて、正例か負例に振る。しかしF1-scoreの場\n",
    "合は正例の割合や正しく予測出来ている割合によって、F1-scoreを最大化する閾値が異なるため、その閾値を求める必要がある。方法として、\n",
    "\n",
    "・0.01~0.99間を0.01刻みで、すべてのスコアを走査し、最良を探す。\n",
    "\n",
    "・最適化アルゴリズムを使う。\n",
    "\n",
    "    ・Nelder-Mead法: 最適化対象となる目的関数が微分可能でなくても使用できる。\n",
    "    \n",
    "    ・COBYLA法: 制約式(制約条件)を設定できる。\n",
    "    \n",
    "    ・SLSQP法: 最適化対象となる目的関数、制約式が微分可能であることを前提とする。\n",
    "    \n",
    "    等。Nelder-MeadやCOBYLAは比較的安定した解が求められる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init_threshold: 0.5 init_score: 0.7221549636803875\n",
      "\n",
      "Nelder-Mead method result:\n",
      " final_simplex: (array([[0.35585937],\n",
      "       [0.35576172]]), array([-0.76296101, -0.76296101]))\n",
      "           fun: -0.7629610069536134\n",
      "       message: 'Optimization terminated successfully.'\n",
      "          nfev: 31\n",
      "           nit: 14\n",
      "        status: 0\n",
      "       success: True\n",
      "             x: array([0.35585937])\n",
      "\n",
      "best_threshold: 0.35585937499999987 best_score: 0.7629610069536134\n",
      "\n",
      "\n",
      "COBYLA method result:\n",
      "     fun: -0.7629701400510878\n",
      "   maxcv: 0.0\n",
      " message: 'Optimization terminated successfully.'\n",
      "    nfev: 22\n",
      "  status: 1\n",
      " success: True\n",
      "       x: array([0.35644531])\n",
      "\n",
      "best_threshold: 0.3564453125 best_score: 0.7629701400510878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "rand = np.random.RandomState(seed=42)\n",
    "# 0~1まで1万刻みでprob生成\n",
    "train_y_prob = np.linspace(0, 1, 10000)\n",
    "\n",
    "# train_y_prob.size分のブール値を真の値として、生成ベクトルを標準化したものを予測値として、それぞれ定義\n",
    "train_y = pd.Series(rand.uniform(0.0, 1.0, train_y_prob.size) < train_y_prob)\n",
    "train_pred_prob = np.clip(train_y_prob * np.exp(rand.standard_normal(train_y_prob.shape) * 0.3), 0.0, 1.0)\n",
    "\n",
    "init_threshold = 0.5\n",
    "init_score = f1_score(train_y, train_pred_prob >= init_threshold)\n",
    "print(f'init_threshold: {init_threshold} init_score: {init_score}')\n",
    "\n",
    "\n",
    "# 目的関数\n",
    "def f1_opt(x):\n",
    "    return -f1_score(train_y, train_pred_prob >= x)\n",
    "\n",
    "\n",
    "# Nelder-Mead法を選択、resultにはベストな閾値が返される\n",
    "result = minimize(f1_opt, x0=np.array([0.5]), method='Nelder-Mead')\n",
    "print('\\nNelder-Mead method result:\\n%s\\n' % result)\n",
    "best_threshold = result['x'].item()\n",
    "best_score = f1_score(train_y, train_pred_prob >= best_threshold)\n",
    "print(f'best_threshold: {best_threshold} best_score: {best_score}\\n')\n",
    "\n",
    "# COBYLA法を選択\n",
    "result = minimize(f1_opt, x0=np.array([0.5]), method='COBYLA', options={'maxiter': 10000, 'catol': 0.8})\n",
    "print('\\nCOBYLA method result:\\n%s\\n' % result)\n",
    "best_threshold = result['x'].item()\n",
    "best_score = f1_score(train_y, train_pred_prob >= best_threshold)\n",
    "print(f'best_threshold: {best_threshold} best_score: {best_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 閾値の最適化をoofで行うべきか？\n",
    "\n",
    "### oof (out-of-fold)\n",
    "\n",
    "交差検証において、分割したfoldの内1つは変数を与えずに予測用（答えを知らない）とし、他を学習用とする。\n",
    "\n",
    "これを、fold数分1つずつずらしながら、すべてのfoldの予測値を作成する。\n",
    "\n",
    "予測値はモデルの評価やスタッキングの特徴量に用いる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　　　"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "閾値の最適化でoofを用いることによって、閾値やスコアのぶれを考慮した最適化が行える。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "threshold: 0.35585937499999987, score_tr: 0.7621823268827232, score_va: 0.7653611210923463\n",
      "Fold 1\n",
      "threshold: 0.35585937499999987, score_tr: 0.7627950455713953, score_va: 0.7634677131644666\n",
      "Fold 2\n",
      "threshold: 0.35585937499999987, score_tr: 0.7621525724423418, score_va: 0.7653131452167928\n",
      "Fold 3\n",
      "threshold: 0.35585937499999987, score_tr: 0.7647197362223269, score_va: 0.7577553154409201\n",
      "\n",
      "thresholds mean:  0.35585937499999987\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "rand = np.random.RandomState(seed=42)\n",
    "# 0~1まで1万刻みでprob生成\n",
    "train_y_prob = np.linspace(0, 1, 10000)\n",
    "\n",
    "# train_y_prob.size分のブール値を真の値として、生成ベクトルを標準化したものを予測値として、それぞれ定義\n",
    "train_y = pd.Series(rand.uniform(0.0, 1.0, train_y_prob.size) < train_y_prob)\n",
    "train_pred_prob = np.clip(train_y_prob * np.exp(rand.standard_normal(train_y_prob.shape) * 0.3), 0.0, 1.0)\n",
    "\n",
    "thresholds = []\n",
    "scores_tr = []\n",
    "scores_va = []\n",
    "\n",
    "kf = KFold(n_splits=4, random_state=42, shuffle=True)\n",
    "for i, (tr_idx, va_idx) in enumerate(kf.split(train_pred_prob)):\n",
    "    tr_pred_prob, va_pred_prob = train_pred_prob[tr_idx], train_pred_prob[va_idx]\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "    \n",
    "    # 目的関数\n",
    "    def f1_opt(x):\n",
    "        return -f1_score(train_y, train_pred_prob >= x)\n",
    "    \n",
    "    result = minimize(f1_opt, x0=np.array([0.5]), method='Nelder-Mead')\n",
    "    threshold = result['x'].item()\n",
    "    score_tr = f1_score(tr_y, tr_pred_prob >= threshold)\n",
    "    score_va = f1_score(va_y, va_pred_prob >= threshold)\n",
    "    print('Fold', i)\n",
    "    print(f'threshold: {threshold}, score_tr: {score_tr}, score_va: {score_va}')\n",
    "    \n",
    "    thresholds.append(threshold)\n",
    "    scores_tr.append(score_tr)\n",
    "    scores_va.append(score_va)\n",
    "\n",
    "    \n",
    "threshold_test = np.mean(thresholds)\n",
    "print('\\nthresholds mean: ', threshold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 予測確率とその調整\n",
    "\n",
    "分類タスクにおいて評価指標の最適化を考えた場合、評価指標が目的関数となっていれば妥当な予測確率を期待できるが、そうでない場合は予測確率に歪みが生じる場合がある。AUCを通した場合は大小関係さえあっていれば問題ないが、loglossの場合は予測確率がずれているとペナルティが生じる。\n",
    "\n",
    "一般的に予測確率が歪むケースとして、\n",
    "\n",
    "・データが十分でない\n",
    "\n",
    "・モデルのアルゴリズム上、妥当な予測確率だすよう最適化されていない場合\n",
    "\n",
    "RandomForestは目的関数をloglossとせず、GBDT、NN、RogisticRegression等とは異なるアルゴリズムで分類をするため、確率は歪んでいる。\n",
    "\n",
    "こういった場合、事後に予測確率を調整することによって、スコアが改善する場合がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 予測確率の調整\n",
    "・予測値をn乗する：　確率を十分に学習できていないと考え、補正として予測値をn乗(0.9~1.1)する後処理を加える。\n",
    "\n",
    "・極端に0や1に近い確率のクリップ：　評価指標にペナルティがある場合、それを避けるために出力する確率をクリップする方法\n",
    "\n",
    "・スタッキング：　スタッキングの2層目のモデルとして、GBDT、NN、RogisticRegression等の妥当な確率を出力するモデルを選定する方法。\n",
    "\n",
    "・CalibratedClassifierCV：　scikit-learnモジュールのCalibratedClassifierCVを用いて、予測確率を補正（較正）する方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression logloss score:  0.07837392262879811\n",
      "RandomForest logloss score:  0.09544270629552579\n",
      "RandomForest logloss score with post-processing:  0.0949390543490502\n"
     ]
    }
   ],
   "source": [
    "## 予測値をn乗する\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# データセットロード\n",
    "cancer = load_breast_cancer()\n",
    "X = cancer.data; y = cancer.target\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr_model = LogisticRegression(random_state=42)\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "lr_model.fit(train_x, train_y)\n",
    "rf_model.fit(train_x, train_y)\n",
    "\n",
    "lr_pred = lr_model.predict_proba(valid_x)[:, 1]\n",
    "rf_pred = rf_model.predict_proba(valid_x)[:, 1]\n",
    "\n",
    "print('LogisticRegression logloss score: ', log_loss(valid_y, lr_pred))\n",
    "print('RandomForest logloss score: ', log_loss(valid_y, rf_pred))\n",
    "print('RandomForest logloss score with post-processing: ', log_loss(valid_y, rf_pred**1.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated RandomForest logloss score:  0.08199515752044927\n"
     ]
    }
   ],
   "source": [
    "## CalibratedClassifierCV\n",
    "## 交差検証同様にデータセットを分割し、訓練と補正をそれぞれ行う\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "# シグモイド関数による補正を選択\n",
    "# 事前学習済みモデルを使う場合は、method='prefit'を指定する\n",
    "calib_rf = CalibratedClassifierCV(rf_model, method='sigmoid', cv=2)\n",
    "calib_rf.fit(train_x, train_y)\n",
    "\n",
    "calib_rf_pred = calib_rf.predict_proba(valid_x)[:, 1]\n",
    "print('Calibrated RandomForest logloss score: ', log_loss(valid_y, calib_rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RF pred stats</th>\n",
       "      <td>114.0</td>\n",
       "      <td>0.619912</td>\n",
       "      <td>0.442806</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Calibrated RF pred stats</th>\n",
       "      <td>114.0</td>\n",
       "      <td>0.628026</td>\n",
       "      <td>0.444807</td>\n",
       "      <td>0.01586</td>\n",
       "      <td>0.023299</td>\n",
       "      <td>0.971116</td>\n",
       "      <td>0.984013</td>\n",
       "      <td>0.985087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count      mean       std      min       25%  \\\n",
       "RF pred stats             114.0  0.619912  0.442806  0.00000  0.020000   \n",
       "Calibrated RF pred stats  114.0  0.628026  0.444807  0.01586  0.023299   \n",
       "\n",
       "                               50%       75%       max  \n",
       "RF pred stats             0.920000  0.990000  1.000000  \n",
       "Calibrated RF pred stats  0.971116  0.984013  0.985087  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 補正前、補正後のRandomForest予測確率の統計量\n",
    "pd.DataFrame(\n",
    "    [pd.Series(rf_pred.ravel()).describe().transpose(), pd.Series(calib_rf_pred.ravel()).describe().transpose()], \n",
    "    index=['RF pred stats', 'Calibrated RF pred stats']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
